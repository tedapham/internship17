{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " %matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn;seaborn.set()\n",
    "import scipy  \n",
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# import scikits.bootstrap as bootstrap  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HCC= pd.read_csv('featureMatrix.csv')\n",
    "HCC.drop('Unnamed: 0',axis=1,inplace = True)\n",
    "codePriority = {'A':0,'B':1,'C':2,'D':3,'E':4}\n",
    "sex = {'F':0,'M':1}\n",
    "HCC['Priority'] = HCC['Priority'].map(codePriority)\n",
    "HCC['Gender'] = HCC['Gender'].map(sex)\n",
    "HCC = HCC[np.isfinite(HCC['Gender'])]\n",
    "#copy feature matrix and label vector\n",
    "Xy = HCC.drop('ChartID',axis=1)\n",
    "Xy['state'] =  Xy['state'].astype('category')\n",
    "Xy['state'] =  Xy['state'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Priority</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Chart_Count</th>\n",
       "      <th>Specialty</th>\n",
       "      <th>state</th>\n",
       "      <th>hasHCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65</td>\n",
       "      <td>12548</td>\n",
       "      <td>Family Medicine</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53</td>\n",
       "      <td>296</td>\n",
       "      <td>Physician Assistant</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>145</td>\n",
       "      <td>Internal Medicine</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>96</td>\n",
       "      <td>Family Medicine</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>285</td>\n",
       "      <td>Family Medicine</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Priority  Gender  Age  Chart_Count            Specialty  state hasHCC\n",
       "0         0     0.0   65        12548      Family Medicine     13   True\n",
       "1         0     1.0   53          296  Physician Assistant     13  False\n",
       "2         0     0.0   42          145    Internal Medicine     15  False\n",
       "3         0     0.0   46           96      Family Medicine     18  False\n",
       "4         0     0.0   64          285      Family Medicine     13   True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.898218\n",
      "0.64474\n",
      "0.643287946633\n"
     ]
    }
   ],
   "source": [
    "data, label = Xy.copy().iloc[:,:-1],Xy.iloc[:,-1]\n",
    "data['Specialty'] = data['Specialty'].astype('category')\n",
    "data['Specialty'] = data['Specialty'].cat.codes\n",
    "train_data, train_label = data.copy().iloc[:500000,:],label[:500000]\n",
    "dev_data,dev_label = data.copy().iloc[500000:550000,:],label[500000:550000]\n",
    "test_data,test_label= data.copy().iloc[550000:,:],label[550000:]\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier().fit(train_data,train_label)\n",
    "print(tree.score(train_data,train_label))\n",
    "print(tree.score(dev_data,dev_label))\n",
    "print(tree.score(test_data,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.832654\n",
      "0.57976\n",
      "0.589829114502\n"
     ]
    }
   ],
   "source": [
    "data, label = Xy.copy().iloc[:,1:-1],Xy.iloc[:,-1]\n",
    "data['Specialty'] = data['Specialty'].astype('category')\n",
    "data['Specialty'] = data['Specialty'].cat.codes\n",
    "train_data, train_label = data.copy().iloc[:500000,:],label[:500000]\n",
    "dev_data,dev_label = data.copy().iloc[500000:550000,:],label[500000:550000]\n",
    "test_data,test_label= data.copy().iloc[550000:,:],label[550000:]\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier().fit(train_data,train_label)\n",
    "print(tree.score(train_data,train_label))\n",
    "print(tree.score(dev_data,dev_label))\n",
    "print(tree.score(test_data,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Chart_Count', 'Age', 'Specialty_Internal Medicine', 'Gender',\n",
       "       'Specialty_Family Medicine', 'Specialty_Surgery',\n",
       "       'Specialty_Physician Assistant', 'Specialty_Institution',\n",
       "       'Specialty_Otolaryngology', 'Specialty_OBGYN', 'Specialty_Technician',\n",
       "       'Specialty_Orthopaedic Surgery', 'Specialty_Psychiatry',\n",
       "       'Specialty_Specialist', 'Specialty_Ophthalmology',\n",
       "       'Specialty_Occupational Therapist', 'Specialty_Allergy',\n",
       "       'Specialty_Nurse Practitioner', 'Specialty_General Practice',\n",
       "       'Specialty_Physical Medicine', 'Specialty_Pediatrics',\n",
       "       'Specialty_Radiology', 'Specialty_Podiatrist', 'Specialty_Podatrist',\n",
       "       'Specialty_Urology', 'Specialty_Nuclear Medicine',\n",
       "       'Specialty_Anesthesiology', 'Specialty_Legal Medicine',\n",
       "       'Specialty_Registered Nurse', 'Specialty_Institution ',\n",
       "       'Specialty_Dermatology', 'Specialty_Pain Medicine',\n",
       "       'Specialty_Plastic Surgery', 'Specialty_Preventive Medicine',\n",
       "       'Specialty_Vendor', 'Specialty_Ambulance', 'Specialty_Psychologist',\n",
       "       'Specialty_Counselor', 'Specialty_Rehabilitation', 'Specialty_Midwife',\n",
       "       'Specialty_Social Worker', 'Specialty_Geneticist',\n",
       "       'Specialty_Nutritionist', 'Specialty_Audiologist',\n",
       "       'Specialty_Physical Therapy', 'Specialty_Dentist',\n",
       "       'Specialty_Transplant', 'Specialty_Acupuncturist',\n",
       "       'Specialty_Chiropractor', 'Specialty_Pathology', 'Specialty_Phlebology',\n",
       "       'Specialty_Pharmacist', 'Specialty_Speech Pathologist',\n",
       "       'Specialty_Sleep Specialist', 'Specialty_Marriage Therapist',\n",
       "       'Specialty_Hospice, Inpatient', 'Specialty_Medical Examiner',\n",
       "       'Specialty_Military', 'Specialty_Doula', 'Specialty_Public Health'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = tree.feature_importances_*(-1)\n",
    "index = importance.argsort()\n",
    "\n",
    "data.columns[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With One Hot Encoding using \n",
      " one tree with Decision tree Classifer the score is 0.6437\n",
      "\n",
      "\n",
      "# of treesin the forest \t score\n",
      "========================================\n",
      "10 0.884958\n",
      "10 \t\t\t\t 0.66202\n",
      "50 0.897858\n",
      "50 \t\t\t\t 0.66536\n",
      "100 0.898198\n",
      "100 \t\t\t\t 0.66708\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "data, label = Xy.copy().iloc[:,:-1],Xy.iloc[:,-1]\n",
    "data['Specialty'] = data['Specialty'].astype('category')\n",
    "data['Specialty'] = data['Specialty'].cat.codes\n",
    "\n",
    "train_data, train_label = data.copy().iloc[:500000,:],label[:500000]\n",
    "dev_data,dev_label = data.copy().iloc[500000:550000,:],label[500000:550000]\n",
    "test_data,test_label= data.copy().iloc[550000:,:],label[550000:]\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier().fit(train_data,train_label)\n",
    "print('With One Hot Encoding using \\n one tree with Decision tree Classifer the score is',tree.score(dev_data,dev_label))\n",
    "\n",
    "print('\\n\\n# of treesin the forest \\t score')\n",
    "print('========================================')\n",
    "for i in [10,50,100]:\n",
    "    forest = RandomForestClassifier(n_estimators = i)\n",
    "    forest.fit(train_data,train_label)\n",
    "    print(i,forest.score(train_data,train_label))\n",
    "    print(i,'\\t\\t\\t\\t',forest.score(dev_data,dev_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67380974138718819"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(test_data,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With One Hot Encoding using \n",
      " one tree with Decision tree Classifer the score is 0.57884\n",
      "\n",
      "\n",
      "# of treesin the forest \t score\n",
      "========================================\n",
      "10 0.821026\n",
      "10 \t\t\t\t 0.58236\n",
      "50 0.832408\n",
      "50 \t\t\t\t 0.58456\n",
      "100 0.832636\n",
      "100 \t\t\t\t 0.58574\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a9ad702b8396>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mforest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'\\t\\t\\t\\t'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdev_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ted.pham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 326\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ted.pham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ted.pham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ted.pham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ted.pham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ted.pham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ted.pham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ted.pham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ted.pham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ted.pham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ted.pham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            self.min_impurity_split)\n\u001b[1;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "data, label = Xy.copy().iloc[:,1:-1],Xy.iloc[:,-1]\n",
    "data['Specialty'] = data['Specialty'].astype('category')\n",
    "data['Specialty'] = data['Specialty'].cat.codes\n",
    "\n",
    "train_data, train_label = data.copy().iloc[:500000,:],label[:500000]\n",
    "dev_data,dev_label = data.copy().iloc[500000:550000,:],label[500000:550000]\n",
    "test_data,test_label= data.copy().iloc[550000:,:],label[550000:]\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier().fit(train_data,train_label)\n",
    "print('With One Hot Encoding using \\n one tree with Decision tree Classifer the score is',tree.score(dev_data,dev_label))\n",
    "\n",
    "print('\\n\\n# of treesin the forest \\t score')\n",
    "print('========================================')\n",
    "for i in [10,50,100,200]:\n",
    "    forest = RandomForestClassifier(n_estimators = i)\n",
    "    forest.fit(train_data,train_label)\n",
    "    print(i,forest.score(train_data,train_label))\n",
    "    print(i,'\\t\\t\\t\\t',forest.score(dev_data,dev_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60038380699990856"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "forest.fit(train_data,train_label)\n",
    "forest.score(test_data,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest.score(test_data,test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding and random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Tree Score 0.57862\n",
      "# of treesin the forest \t score\n",
      "=======================================\n",
      "1 \t\t\t\t 0.5673\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.60      0.60      0.60     26829\n",
      "       True       0.53      0.53      0.53     23171\n",
      "\n",
      "avg / total       0.57      0.57      0.57     50000\n",
      "\n",
      "5 \t\t\t\t 0.5787\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.61      0.60      0.60     26829\n",
      "       True       0.54      0.56      0.55     23171\n",
      "\n",
      "avg / total       0.58      0.58      0.58     50000\n",
      "\n",
      "10 \t\t\t\t 0.58194\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.61      0.61      0.61     26829\n",
      "       True       0.55      0.55      0.55     23171\n",
      "\n",
      "avg / total       0.58      0.58      0.58     50000\n",
      "\n",
      "20 \t\t\t\t 0.58344\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.61      0.60      0.61     26829\n",
      "       True       0.55      0.56      0.56     23171\n",
      "\n",
      "avg / total       0.58      0.58      0.58     50000\n",
      "\n",
      "50 \t\t\t\t 0.58566\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.62      0.60      0.61     26829\n",
      "       True       0.55      0.56      0.56     23171\n",
      "\n",
      "avg / total       0.59      0.59      0.59     50000\n",
      "\n",
      "100 \t\t\t\t 0.58688\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.62      0.60      0.61     26829\n",
      "       True       0.55      0.57      0.56     23171\n",
      "\n",
      "avg / total       0.59      0.59      0.59     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data, label = Xy.copy().iloc[:,1:-1],Xy.iloc[:,-1]\n",
    "data['Specialty'] = data['Specialty'].astype('category')\n",
    "data['Specialty'] = data['Specialty'].cat.codes\n",
    "\n",
    "train_data, train_label = data.copy().iloc[:500000,:],label[:500000]\n",
    "dev_data,dev_label = data.copy().iloc[500000:550000,:],label[500000:550000]\n",
    "test_data,test_label= data.copy().iloc[550000:,:],label[550000:]\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier().fit(train_data,train_label)\n",
    "print('Single Tree Score',tree.score(dev_data,dev_label))\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print('# of treesin the forest \\t score')\n",
    "print('=======================================')\n",
    "for i in [1,5,10,20,50,100]:\n",
    "    forest = RandomForestClassifier(n_estimators = i)\n",
    "    forest.fit(train_data,train_label)\n",
    "    print(i,'\\t\\t\\t\\t',forest.score(dev_data,dev_label))\n",
    "    pred = forest.predict(dev_data)\n",
    "    print(classification_report(dev_label,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count TRUE/FALSE for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "priority = pd.merge(chart_MRR,chart_MCC,on='ChartID',how='inner')\n",
    "\n",
    "display(\"priority.groupby('Priority').count()\",\"priority.groupby('Priority').agg({'hasHCC':sum})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = priority.groupby('Priority').agg({'hasHCC':sum})\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Priority\n",
       "A    0.452150\n",
       "B    0.644587\n",
       "C    0.261686\n",
       "D    0.059837\n",
       "E    0.078831\n",
       "Name: hasHCC, dtype: float64"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k['hasHCC']/[278315,211624,14162,36750,31041]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChartID</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Chart_Count</th>\n",
       "      <th>Specialty</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasHCC</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>301290</td>\n",
       "      <td>301290</td>\n",
       "      <td>301290</td>\n",
       "      <td>301290</td>\n",
       "      <td>301290</td>\n",
       "      <td>301290</td>\n",
       "      <td>301290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>270602</td>\n",
       "      <td>270602</td>\n",
       "      <td>270602</td>\n",
       "      <td>270602</td>\n",
       "      <td>270602</td>\n",
       "      <td>270602</td>\n",
       "      <td>270602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ChartID  Priority  Gender     Age  Chart_Count  Specialty   state\n",
       "hasHCC                                                                   \n",
       "False    301290    301290  301290  301290       301290     301290  301290\n",
       "True     270602    270602  270602  270602       270602     270602  270602"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priority.groupby('hasHCC').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5317474041643414"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "270602/(207602 + 301290)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Tree Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# of treesin the forest \t score\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'GradientBoostingClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0908c1147465>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n\\n# of treesin the forest \\t score'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mforest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m' \\t\\t\\t\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdev_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GradientBoostingClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "data, label = Xy.copy().iloc[:,:-1],Xy.iloc[:,-1]\n",
    "data['Specialty'] = data['Specialty'].astype('category')\n",
    "data['Specialty'] = data['Specialty'].cat.codes\n",
    "\n",
    "train_data, train_label = data.copy().iloc[:500000,:],label[:500000]\n",
    "dev_data,dev_label = data.copy().iloc[500000:550000,:],label[500000:550000]\n",
    "test_data,test_label= data.copy().iloc[550000:,:],label[550000:]\n",
    "\n",
    "print('\\n\\n# of treesin the forest \\t score')\n",
    "\n",
    "forest = GradientBoostingClassifier(n_estimators = 200,learning_rate=0.1)\n",
    "forest.fit(train_data,train_label)\n",
    "print('\\t', i,' \\t\\t\\t\\t', forest.score(dev_data,dev_label))\n",
    "\n",
    "importance = forest.feature_importances_*(-1)\n",
    "index = importance.argsort()\n",
    "\n",
    "data.columns[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# of treesin the forest \t score\n",
      "========================================\n",
      "\t 1  \t\t\t\t 0.53658\n",
      "\t 5  \t\t\t\t 0.58738\n",
      "\t 10  \t\t\t\t 0.59256\n",
      "\t 20  \t\t\t\t 0.5926\n",
      "\t 50  \t\t\t\t 0.59608\n",
      "\t 100  \t\t\t\t 0.60218\n"
     ]
    }
   ],
   "source": [
    "data, label = Xy.copy().iloc[:,1:-1],Xy.iloc[:,-1]\n",
    "data['Specialty'] = data['Specialty'].astype('category')\n",
    "data['Specialty'] = data['Specialty'].cat.codes\n",
    "\n",
    "train_data, train_label = data.copy().iloc[:500000,:],label[:500000]\n",
    "dev_data,dev_label = data.copy().iloc[500000:550000,:],label[500000:550000]\n",
    "test_data,test_label= data.copy().iloc[550000:,:],label[550000:]\n",
    "\n",
    "print('\\n\\n# of treesin the forest \\t score')\n",
    "print('========================================')\n",
    "for i in [1,5,10,20,50,100]:\n",
    "    forest = GradientBoostingClassifier(n_estimators = i,learning_rate=0.1)\n",
    "    forest.fit(train_data,train_label)\n",
    "    print('\\t', i,' \\t\\t\\t\\t', forest.score(dev_data,dev_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68003\n",
      "\t 200  \t\t\t\t 0.69132\n",
      "0.701452983643\n"
     ]
    }
   ],
   "source": [
    "data, label = Xy.copy().iloc[:,:-1],Xy.iloc[:,-1]\n",
    "data['Specialty'] = data['Specialty'].astype('category')\n",
    "data['Specialty'] = data['Specialty'].cat.codes\n",
    "\n",
    "train_data, train_label = data.copy().iloc[:500000,:],label[:500000]\n",
    "dev_data,dev_label = data.copy().iloc[500000:550000,:],label[500000:550000]\n",
    "test_data,test_label= data.copy().iloc[550000:,:],label[550000:]\n",
    "\n",
    "forest = GradientBoostingClassifier(n_estimators = 200,learning_rate=0.1)\n",
    "forest.fit(train_data,train_label)\n",
    "print(forest.score(train_data,train_label))\n",
    "print('\\t', i,' \\t\\t\\t\\t', forest.score(dev_data,dev_label))\n",
    "print(forest.score(test_data,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.597648\n",
      "\t 200  \t\t\t\t 0.6\n",
      "0.612948917116\n"
     ]
    }
   ],
   "source": [
    "data, label = Xy.copy().iloc[:,1:-2],Xy.iloc[:,-1]\n",
    "data['Specialty'] = data['Specialty'].astype('category')\n",
    "data['Specialty'] = data['Specialty'].cat.codes\n",
    "\n",
    "train_data, train_label = data.copy().iloc[:500000,:],label[:500000]\n",
    "dev_data,dev_label = data.copy().iloc[500000:550000,:],label[500000:550000]\n",
    "test_data,test_label= data.copy().iloc[550000:,:],label[550000:]\n",
    "\n",
    "forest = GradientBoostingClassifier(n_estimators = 200,learning_rate=0.1)\n",
    "forest.fit(train_data,train_label)\n",
    "print(forest.score(train_data,train_label))\n",
    "print('\\t', i,' \\t\\t\\t\\t', forest.score(dev_data,dev_label))\n",
    "print(forest.score(test_data,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.598028\n",
      "\t 200  \t\t\t\t 0.60826\n",
      "0.610161747236\n"
     ]
    }
   ],
   "source": [
    "data, label = Xy.copy().iloc[:,2:-1],Xy.iloc[:,-1]\n",
    "data['Specialty'] = data['Specialty'].astype('category')\n",
    "data['Specialty'] = data['Specialty'].cat.codes\n",
    "\n",
    "train_data, train_label = data.copy().iloc[:500000,:],label[:500000]\n",
    "dev_data,dev_label = data.copy().iloc[500000:550000,:],label[500000:550000]\n",
    "test_data,test_label= data.copy().iloc[550000:,:],label[550000:]\n",
    "\n",
    "forest = GradientBoostingClassifier(n_estimators = 200,learning_rate=0.1)\n",
    "forest.fit(train_data,train_label)\n",
    "print(forest.score(train_data,train_label))\n",
    "print('\\t', i,' \\t\\t\\t\\t', forest.score(dev_data,dev_label))\n",
    "print(forest.score(test_data,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59563\n",
      "\t 200  \t\t\t\t 0.59862\n",
      "0.611486795212\n"
     ]
    }
   ],
   "source": [
    "data, label = Xy.copy().iloc[:,2:-2],Xy.iloc[:,-1]\n",
    "data['Specialty'] = data['Specialty'].astype('category')\n",
    "data['Specialty'] = data['Specialty'].cat.codes\n",
    "\n",
    "train_data, train_label = data.copy().iloc[:500000,:],label[:500000]\n",
    "dev_data,dev_label = data.copy().iloc[500000:550000,:],label[500000:550000]\n",
    "test_data,test_label= data.copy().iloc[550000:,:],label[550000:]\n",
    "\n",
    "forest = GradientBoostingClassifier(n_estimators = 200,learning_rate=0.1)\n",
    "forest.fit(train_data,train_label)\n",
    "print(forest.score(train_data,train_label))\n",
    "print('\\t', i,' \\t\\t\\t\\t', forest.score(dev_data,dev_label))\n",
    "print(forest.score(test_data,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, label = Xy.copy().iloc[:,1:-2],Xy.iloc[:,-1]\n",
    "data['Specialty'] = data['Specialty'].astype('category')\n",
    "data['Specialty'] = data['Specialty'].cat.codes\n",
    "\n",
    "train_data, train_label = data.copy().iloc[:500000,:],label[:500000]\n",
    "dev_data,dev_label = data.copy().iloc[500000:550000,:],label[500000:550000]\n",
    "test_data,test_label= data.copy().iloc[550000:,:],label[550000:]\n",
    "\n",
    "forest = GradientBoostingClassifier(n_estimators = 200,learning_rate=0.1)\n",
    "forest.fit(train_data,train_label)\n",
    "print(forest.score(train_data,train_label))\n",
    "print('\\t', i,' \\t\\t\\t\\t', forest.score(dev_data,dev_label))\n",
    "print(forest.score(test_data,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.600572\n",
      "\t 200  \t\t\t\t 0.60654\n",
      "0.613177373664\n"
     ]
    }
   ],
   "source": [
    "data, label = Xy.copy().iloc[:,1:-1],Xy.iloc[:,-1]\n",
    "data['Specialty'] = data['Specialty'].astype('category')\n",
    "data['Specialty'] = data['Specialty'].cat.codes\n",
    "\n",
    "train_data, train_label = data.copy().iloc[:500000,:],label[:500000]\n",
    "dev_data,dev_label = data.copy().iloc[500000:550000,:],label[500000:550000]\n",
    "test_data,test_label= data.copy().iloc[550000:,:],label[550000:]\n",
    "\n",
    "forest = GradientBoostingClassifier(n_estimators = 200,learning_rate=0.1)\n",
    "forest.fit(train_data,train_label)\n",
    "print(forest.score(train_data,train_label))\n",
    "print('\\t', i,' \\t\\t\\t\\t', forest.score(dev_data,dev_label))\n",
    "print(forest.score(test_data,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Specialty', 'Chart_Count', 'Age', 'state', 'Gender'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = forest.feature_importances_*(-1)\n",
    "index = importance.argsort()\n",
    "\n",
    "data.columns[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.63      0.67      0.65     26829\n",
      "       True       0.58      0.54      0.56     23171\n",
      "\n",
      "avg / total       0.61      0.61      0.61     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = forest.predict(dev_data)\n",
    "print(classification_report(dev_label,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# of treesin the forest \t score\n",
      "========================================\n",
      "\t 1  \t\t\t\t 0.53658\n",
      "\t 5  \t\t\t\t 0.58906\n",
      "\t 10  \t\t\t\t 0.58854\n",
      "\t 20  \t\t\t\t 0.58856\n",
      "\t 50  \t\t\t\t 0.5943\n",
      "\t 100  \t\t\t\t 0.59946\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7e1dd01b2cb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mforest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m' \\t\\t\\t\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdev_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ted.pham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1028\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1029\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ted.pham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1082\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ted.pham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 787\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ted.pham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1030\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ted.pham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            self.min_impurity_split)\n\u001b[1;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data, label = Xy.copy().iloc[:,1:-1],Xy.iloc[:,-1]\n",
    "data = pd.get_dummies(data,columns =['Specialty']) # One Hot Encoding\n",
    "train_data, train_label = data.copy().iloc[:500000,:],label[:500000]\n",
    "dev_data,dev_label = data.copy().iloc[500000:550000,:],label[500000:550000]\n",
    "test_data,test_label= data.copy().iloc[550000:,:],label[550000:]\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "print('\\n\\n# of treesin the forest \\t score')\n",
    "print('========================================')\n",
    "for i in [1,5,10,20,50,100,200,500]:\n",
    "    forest = GradientBoostingClassifier(n_estimators = i,learning_rate=0.1)\n",
    "    forest.fit(train_data,train_label)\n",
    "    print('\\t', i,' \\t\\t\\t\\t', forest.score(dev_data,dev_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# of treesin the forest \t score\n",
      "========================================\n",
      "0.67462\n",
      "\t 200  \t\t\t\t 0.6851\n",
      "0.695056200311\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "data, label = Xy.copy().iloc[:,:-1],Xy.iloc[:,-1]\n",
    "data['Specialty'] = data['Specialty'].astype('category')\n",
    "data['Specialty'] = data['Specialty'].cat.codes\n",
    "\n",
    "train_data, train_label = data.copy().iloc[:500000,:],label[:500000]\n",
    "dev_data,dev_label = data.copy().iloc[500000:550000,:],label[500000:550000]\n",
    "test_data,test_label= data.copy().iloc[550000:,:],label[550000:]\n",
    "\n",
    "print('\\n\\n# of treesin the forest \\t score')\n",
    "print('========================================')\n",
    "\n",
    "forest = AdaBoostClassifier(n_estimators = 200)\n",
    "forest.fit(train_data,train_label)\n",
    "print(forest.score(train_data,train_label))\n",
    "print('\\t', i,' \\t\\t\\t\\t', forest.score(dev_data,dev_label))\n",
    "print(forest.score(test_data,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# of treesin the forest \t score\n",
      "========================================\n",
      "0.59216\n",
      "\t 200  \t\t\t\t 0.6006\n",
      "0.600475189619\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "data, label = Xy.copy().iloc[:,1:-1],Xy.iloc[:,-1]\n",
    "data['Specialty'] = data['Specialty'].astype('category')\n",
    "data['Specialty'] = data['Specialty'].cat.codes\n",
    "\n",
    "train_data, train_label = data.copy().iloc[:500000,:],label[:500000]\n",
    "dev_data,dev_label = data.copy().iloc[500000:550000,:],label[500000:550000]\n",
    "test_data,test_label= data.copy().iloc[550000:,:],label[550000:]\n",
    "\n",
    "print('\\n\\n# of treesin the forest \\t score')\n",
    "print('========================================')\n",
    "\n",
    "forest = AdaBoostClassifier(n_estimators = 200)\n",
    "forest.fit(train_data,train_label)\n",
    "print(forest.score(train_data,train_label))\n",
    "print('\\t', i,' \\t\\t\\t\\t', forest.score(dev_data,dev_label))\n",
    "print(forest.score(test_data,test_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# of treesin the forest \t score\n",
      "========================================\n",
      "\t 100  \t\t\t\t 0.6851\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "data, label = Xy.copy().iloc[:,0:-1],Xy.iloc[:,-1]\n",
    "data['Specialty'] = data['Specialty'].astype('category')\n",
    "data['Specialty'] = data['Specialty'].cat.codes\n",
    "\n",
    "train_data, train_label = data.copy().iloc[:500000,:],label[:500000]\n",
    "dev_data,dev_label = data.copy().iloc[500000:550000,:],label[500000:550000]\n",
    "test_data,test_label= data.copy().iloc[550000:,:],label[550000:]\n",
    "\n",
    "print('\\n\\n# of treesin the forest \\t score')\n",
    "print('========================================')\n",
    "\n",
    "forest = AdaBoostClassifier(n_estimators = 200)\n",
    "forest.fit(train_data,train_label)\n",
    "print('\\t', i,' \\t\\t\\t\\t', forest.score(dev_data,dev_label))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
